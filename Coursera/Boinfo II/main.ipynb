{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composition(k, text):\n",
    "    \"\"\"\n",
    "    Assuming k is an integer and text is a string of nucleotides, return the list of all k-mers in text (including repeated k-mers).\n",
    "    >>> composition(5, \"CAATCCAAC\")\n",
    "    ['CAATC', 'AATCC', 'ATCCA', 'TCCAA', 'CCAAC']\n",
    "    \"\"\"\n",
    "    kmers = []\n",
    "    length = len(text)\n",
    "    for i in range(0, length-k+1):\n",
    "        kmers.append(text[i:i+k])\n",
    "    #print(*kmers, sep=\" \")\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PathToGenome(path):\n",
    "    \"\"\"\n",
    "    Assuming the input is a sequence path of n k-mers split with spaces, the consecutive ones of which shares an overlap whose length is k-1;\n",
    "    return an assembled string.\n",
    "    >>> PathToGenome(\"ACCGA CCGAA CGAAG GAAGC AAGCT\")\n",
    "    ACCGAAGCT\n",
    "    \"\"\"\n",
    "    kmers = path.split() if type(path) == str else path\n",
    "    return kmers[0] + ''.join(kmer[-1] for kmer in kmers[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Overlap(patterns):\n",
    "    \"\"\"\n",
    "    Assuming the input is a string of k-mers split with spaces, return the overlap graph in the form of an adjacency list\n",
    "    >>> Overlap(\"ATGCG GCATG CATGC AGGCA GGCAT GGCAC\")\n",
    "    {'GCATG': ['CATGC'],\n",
    "    'CATGC': ['ATGCG'],\n",
    "    'AGGCA': ['GGCAT', 'GGCAC'],\n",
    "    'GGCAT': ['GCATG']}\n",
    "    \"\"\"\n",
    "    kmers = patterns.split()\n",
    "    prefix = {kmer: kmer[:-1] for kmer in kmers}\n",
    "    suffix = {kmer: kmer[1:] for kmer in kmers}\n",
    "\n",
    "    adjacency = {kmer: [] for kmer in kmers}\n",
    "    for kmer in kmers:\n",
    "        for key, value in prefix.items():\n",
    "            if suffix[kmer] == value:\n",
    "                adjacency[kmer].append(key)\n",
    "    \n",
    "    # Remove all the keys in adjacency if its value is empty list\n",
    "    adjacency = {key: value for key, value in adjacency.items() if value}\n",
    "    # print('\\n'.join(f'{kmer}: {\" \".join(adj)}' for kmer, adj in adjacency.items()))\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeBruijn_text(k, text):\n",
    "    \"\"\"\n",
    "    Assuming k is an integer greater than 0 and text is a string whose length is greater than or equal to k,\n",
    "    the output is an adjacency list where all the identically labelled nodes are glued.\n",
    "    >>> DeBruijn_text(4, \"AAGATTCTCTAAGA\")\n",
    "    {'AAG': ['AGA', 'AGA'],\n",
    "    'AGA': ['GAT'],\n",
    "    'GAT': ['ATT'],\n",
    "    'ATT': ['TTC'],\n",
    "    'TTC': ['TCT'],\n",
    "    'TCT': ['CTC', 'CTA'],\n",
    "    'CTC': ['TCT'],\n",
    "    'CTA': ['TAA'],\n",
    "    'TAA': ['AAG']}\n",
    "    \"\"\"\n",
    "    length = len(text)\n",
    "    kmers = [text[i:i+k-1] for i in range(0, length-k+2)]\n",
    "    adjacency = {kmer: [] for kmer in kmers}\n",
    "    for i in range(0, len(kmers)-1):\n",
    "        adjacency[kmers[i]].append(kmers[i+1])\n",
    "    \n",
    "    # Remove all the keys in adjacency if its value is empty list\n",
    "    adjacency = {key: value for key, value in adjacency.items() if value}\n",
    "\n",
    "    #print('\\n'.join(f'{kmer}: {\" \".join(adj)}' for kmer, adj in adjacency.items()))\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeBruijn_pattern(patterns):\n",
    "    \"\"\"\n",
    "    Assume the input is a collection of k-mer patterns split with spaces,\n",
    "    the output is an adjacency list of the de Bruijn graph.\n",
    "    >>> DeBruijn_pattern(\"GAGG CAGG GGGG GGGA CAGG AGGG GGAG\")\n",
    "    {'GAG': ['AGG'],\n",
    "    'CAG': ['AGG', 'AGG'],\n",
    "    'GGG': ['GGG', 'GGA'],\n",
    "    'AGG': ['GGG'],\n",
    "    'GGA': ['GAG']}\n",
    "    \"\"\"\n",
    "    patterns = patterns.split()\n",
    "    k = len(patterns[0])\n",
    "    adjacency = {kmer[:k-1]: [] for kmer in patterns}\n",
    "\n",
    "    for kmer in patterns:\n",
    "        adjacency[kmer[:k-1]].append(kmer[1:])\n",
    "    \n",
    "    #print('\\n'.join(f'{kmer}: {\" \".join(adj)}' for kmer, adj in adjacency.items()))\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EulerianCycle(graph):\n",
    "    \"\"\"\n",
    "    Assume the input is a strongly connected directed graph in the form of an adjacency list, the output is an Eulerian cycle.\n",
    "    >>> EulerianCycle(\n",
    "    '''\n",
    "    0: 3\n",
    "    1: 0\n",
    "    2: 1 6\n",
    "    3: 2\n",
    "    4: 2\n",
    "    5: 4\n",
    "    6: 5 8\n",
    "    7: 9\n",
    "    8: 7\n",
    "    9: 6\n",
    "    ''')\n",
    "    ['2', '6', '8', '7', '9', '6', '5', '4', '2', '1', '0', '3', '2']\n",
    "    \"\"\"\n",
    "    import random\n",
    "\n",
    "    # Re-format the input and generate a graph dictionary where the key is node and value is a list consisting of its adjacent nodes, e.g., graph = {\"a\": [\"b\", \"c\"]}\n",
    "    if type(graph) == str:\n",
    "        node_graph = [i for i in [item.strip() for item in graph.split(\"\\n\")] if i != \"\"]\n",
    "        graph = {str(key): list(map(str, value.split())) for key, value in (item.split(\": \") for item in node_graph)}\n",
    "\n",
    "    start = random.choice(list(graph.keys()))\n",
    "    cycle = [start]\n",
    "    while graph != {}:\n",
    "        if cycle[0] == cycle[-1] and cycle[-1] not in graph:\n",
    "            new_start = random.choice([node for node in cycle if node in graph.keys()])\n",
    "            cycle = cycle[cycle.index(new_start):] + cycle[1:cycle.index(new_start)+1]\n",
    "        else:\n",
    "            next_step = random.choice(graph[cycle[-1]])\n",
    "            graph[cycle[-1]].remove(next_step)\n",
    "            cycle.append(next_step)\n",
    "            graph = {key: value for key, value in graph.items() if value}\n",
    "    #print(\" \".join(str(x) for x in cycle))\n",
    "    return cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EulerianPath(graph):\n",
    "    \"\"\"\n",
    "    Assume the input is a nearly balanced directed graph, the output is its Eulerian path.\n",
    "    >>> EulerianPath(\n",
    "    '''\n",
    "    0: 2\n",
    "    1: 3\n",
    "    2: 1\n",
    "    3: 0 4\n",
    "    6: 3 7\n",
    "    7: 8\n",
    "    8: 9\n",
    "    9: 6\n",
    "    ''')\n",
    "    ['6', '7', '8', '9', '6', '3', '0', '2', '1', '3', '4']\n",
    "    \"\"\"\n",
    "    import random\n",
    "    from collections import deque\n",
    "\n",
    "    # Re-format the input and generate a graph dictionary where the key is node and value is a set consisting of its adjacent nodes, e.g., graph = {\"a\": [\"b\", \"c\"]}\n",
    "    if isinstance(graph, str):\n",
    "        graph = dict(item.split(\": \") for item in graph.strip().split(\"\\n\"))\n",
    "        graph = {key.strip(): value.split() for key, value in graph.items()}\n",
    "    nodes = set(graph.keys()) | {v for values in graph.values() for v in values}\n",
    "\n",
    "    # Initialize in- and out-degree dictionaries, calculate in- and out-degrees for each node\n",
    "    in_degree = {node: 0 for node in nodes}\n",
    "    out_degree = {node: 0 for node in nodes}\n",
    "    for node, adjacents in graph.items():\n",
    "        out_degree[node] += len(adjacents)\n",
    "        for adjacent in adjacents:\n",
    "            in_degree[adjacent] += 1\n",
    "\n",
    "    # Find the imbalanced nodes to determine start and end of the Eulerian path\n",
    "    start, end = None, None\n",
    "    for node in nodes:\n",
    "        if in_degree[node] < out_degree[node]:\n",
    "            start = node\n",
    "        elif in_degree[node] > out_degree[node]:\n",
    "            end = node\n",
    "    \n",
    "    # Append one directed edge from the end to the start, and generate an Eulerian cycle\n",
    "    if end in graph:\n",
    "        graph[end].append((start, \"artificial\"))\n",
    "    else:\n",
    "        graph[end] = [(start, \"artificial\")]\n",
    "\n",
    "    cycle = deque([start])\n",
    "    start_index = 0\n",
    "    while graph:\n",
    "        current_node = cycle[-1]\n",
    "        if current_node in graph:\n",
    "            # Pick the next node and remove it from the current node's adjacency list\n",
    "            next_node = graph[current_node].pop()\n",
    "            cycle.append(next_node)\n",
    "            # If the current node's adjacency list is empty, remove the node from the graph\n",
    "            if not graph[current_node]:\n",
    "                del graph[current_node]\n",
    "        else:\n",
    "            # Rotate the cycle to find a new starting point with available edges\n",
    "            cycle.rotate(-1)\n",
    "            start_index += 1\n",
    "    \n",
    "    cycle = list(cycle)\n",
    "    # Find the artificial edge\n",
    "    for index, node in enumerate(cycle):\n",
    "        if isinstance(node, tuple) and node[1] == \"artificial\":\n",
    "            # Remove the marker and break the cycle\n",
    "            cycle[index] = node[0]\n",
    "            path = cycle[index + 1:] + cycle[:index]\n",
    "            break\n",
    "    \n",
    "    #print(\" \".join(str(x) for x in path))\n",
    "    return path\n",
    "\n",
    "EulerianPath(\n",
    "    '''\n",
    "    0: 1\n",
    "1: 2 4\n",
    "2: 3\n",
    "3: 0 7\n",
    "4: 5\n",
    "5: 6\n",
    "6: 1\n",
    "9: 3\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringReconstruction(k, patterns):\n",
    "    \"\"\"\n",
    "    Assume the input is an integer k followed by a list of k-mers patterns,\n",
    "    the output is a string with k-mer composition equal to patterns.\n",
    "    >>> StringReconstruction(4, \"CTTA ACCA TACC GGCT GCTT TTAC\")\n",
    "    GGCTTACCA\n",
    "    \"\"\"\n",
    "    dB = DeBruijn_pattern(patterns)\n",
    "    path = EulerianPath(dB)\n",
    "    Text = PathToGenome(path)\n",
    "    return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryString(k):\n",
    "    \"\"\"\n",
    "    Assume the input is an integer k > 0, the output is a list colletion of all possible binary k-mers\n",
    "    >>> BinaryString(3)\n",
    "    ['000', '001', '010', '011', '100', '101', '110', '111']\n",
    "    \"\"\"\n",
    "    if k == 1:\n",
    "        return [\"0\", \"1\"]\n",
    "    else:\n",
    "        return [kmer + bit for kmer in BinaryString(k-1) for bit in [\"0\", \"1\"]]\n",
    "\n",
    "def CircularString(k):\n",
    "    \"\"\"\n",
    "    Assume the input is an integer k > 0, the output is a list of unique k-universal circular string\n",
    "    and the total number of all unique circular strings.\n",
    "    >>> CircularString(3)\n",
    "    (['10001110', '00010111'], 2)\n",
    "    \"\"\"\n",
    "    # Generate a binary k-mer list that includes all the possibilities\n",
    "    binary_kmer = BinaryString(k)\n",
    "    cycles = []\n",
    "    for i in range(1000):\n",
    "        path = EulerianCycle(DeBruijn_pattern(\" \".join(binary_kmer)))\n",
    "        Text = PathToGenome(path)\n",
    "        cycles.append(Text[:-k+1]) # To remove the overlap whose length is k-1\n",
    "    \n",
    "    # Make a list composed of unique k-universal circular strings\n",
    "    cycles = list(set(cycles)) # Make every element in the cycles unique\n",
    "    sorted_substrings = {}\n",
    "\n",
    "    for cycle in cycles:\n",
    "        double_cycle = cycle + cycle # Double the cycle to make a linearized string\n",
    "        substrings = [double_cycle[i:i+len(cycle)] for i in range(len(cycle))] # Create a list which includes all the k-mers whose length is the length of cycle\n",
    "        sorted_substrings[\" \".join(sorted(substrings))] = cycle # Discard all the strings that have the same k-mers\n",
    "\n",
    "    return list(sorted_substrings.values()), len(sorted_substrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PairedComposition(k, d, Text):\n",
    "    \"\"\"\n",
    "    Assume the input k, d are integers, k > 0, d >= 0, and Text is a string whose length is >= 2k + d,\n",
    "    the output is a list consisting of all pattern combinations in the form of (Pattern1|Pattern2),\n",
    "    the length of pattern is k and their distance inbetween is d\n",
    "    >>> PairedComposition(3, 2, \"TAATGCCATGGGATGTT\")\n",
    "    ['(AAT|CAT)',\n",
    "    '(ATG|ATG)',\n",
    "    '(ATG|ATG)',\n",
    "    '(CAT|GAT)',\n",
    "    '(CCA|GGA)',\n",
    "    '(GCC|GGG)',\n",
    "    '(GGG|GTT)',\n",
    "    '(TAA|CCA)',\n",
    "    '(TGC|TGG)',\n",
    "    '(TGG|TGT)']\n",
    "    \"\"\"\n",
    "    return sorted([\"(\" + Text[i:i+k] + \"|\" + Text[i+k+d:i+d+2*k] + \")\" for i in range(len(Text)-(2*k)-d+1)])\n",
    "\n",
    "PairedComposition(3, 2, \"TAATGCCATGGGATGTT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringSpelledByGappedPatterns(k, d, path):\n",
    "    \"\"\"\n",
    "    Assume the inputs are integers k and d, and an Eulerian path whose nodes are combinations of pre- and suffixes,\n",
    "    the output is a collapsed single string.\n",
    "    >>> StringSpelledByGappedPatterns(4, 2, \"GACC|GCGC ACCG|CGCC CCGA|GCCG CGAG|CCGG GAGC|CGGA\")\n",
    "    'GACCGAGCGCCGGA'\n",
    "    \"\"\"\n",
    "    path = path.split() if type(path) == str else path\n",
    "    first_string, second_string = PathToGenome([node[:k] for node in path]), PathToGenome([node[-k:] for node in path])\n",
    "    symbol = first_string[k+d:]\n",
    "    return \"There is no string spelled by the gapped patterns\" if symbol != second_string[:len(symbol)] else first_string[:k+d] + second_string\n",
    "\n",
    "def PairedCompositionGraph(k, d, collection):\n",
    "    \"\"\"\n",
    "    Assume the input k, d are integers, k > 0, d >= 0, and collection is a set of paired k-mers,\n",
    "    the output is a string with (k, d)-mer composition equal to collection\n",
    "    >>> PairedCompositionGraph(4, 2, \"GAGA|TTGA TCGT|GATG CGTG|ATGT TGGT|TGAG GTGA|TGTT GTGG|GTGA TGAG|GTTG GGTC|GAGA GTCG|AGAT\")\n",
    "    GTGGTCGTGAGATGTTGA\n",
    "    \"\"\"\n",
    "    edges = [comb.split(\"|\") for comb in collection.split(\" \")] if type(collection) == str else collection\n",
    "    nodes = [] # All the possible pre- and suffixes\n",
    "    for edge in edges:\n",
    "        nodes.append([edge[i][:-1] for i in [0, 1]]) # All the grouped prefixes\n",
    "        nodes.append([edge[i][1:] for i in [0, 1]]) # All the grouped suffixes\n",
    "    \n",
    "    # Generate a De Bruijn adjacency list for all the nodes\n",
    "    DeBruijn = {\"|\".join(node): [] for node in nodes}\n",
    "    for edge in edges:\n",
    "        DeBruijn[\"|\".join([edge[i][:-1] for i in [0, 1]])].append(\"|\".join([edge[i][1:] for i in [0, 1]]))\n",
    "\n",
    "    Eulerian = EulerianPath(DeBruijn)\n",
    "    \n",
    "    return StringSpelledByGappedPatterns(k-1, d+1, Eulerian) # Because in the Eulerian path the nodes are 1-nt shorter than the edge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
